please create a windows voice assistant for me. I want hands-free interface, wakeword via openwakeword or porcupine, stt with whisper (i'm using an arc a370m 4gb gpu- optimize the whisper.cpp file to use this gpu) - and tts using the current "best" model (in think the lowest tier imworld is tops on the AA leadboard at the moment - here are sme api key s you can use for integrating that :

assemblyai api key: 30c52b1ae015443d8d45e3b859937946

inworld api WVFlUWxzNDRYTkk2R1JnMWdtVXpxSkJ1eVZnaGdiZlA6RUR6TWFzakNYVUZoUmN4Szd6NFlLelhRVTJUYTczZktMamNNN1hHVkFjNURIRmFhcmREVUQ4M3kzd1EwZ1JISg==

inworld jwt key YQeQls44XNI6GRg1gmUzqJBuyVghgbfP

inworld jwt secret EDzMasjCXUFhRcxK7z4YKzXQU2Ta73fKLjcM7XGVAc5DHFaardDUD83y3wQ0gRHJ


I'm not sure what assemblyAI is all about - but the more sst and tts providers you can support the better (i dont use openai 
but you can leave it as an option - just make sure its not default - i prefer to use gemini and openrouter models 
for stict LLM processing of text files - If you can make the system able to word with a "push to talk" as well (maybe not to the assistabt; but just to use the stt ability to transccript voiec into a text box - use the method where you copy the clipboard contents to a cache somewhre, transcribe the audio and then copy it to the clipboard and paspte at cursor location; and then copy original clipboard contents back to the clipboard so its transparent to the user. IO would also like a "press hotkey to start  abd then press hotkey again to stop" capabilities if possible (if you can set both of these to teh fn key that would be sweet - if not; just a left hand key combo is fine - ideally the interace is yo press and hold - and its push to talk, trasncription - if you let go; then its on ; and you press it again to end the transcription.  and then maybe a differnt key combo to start the voice assistant (with an arbitrary model selection for the backend selectable via api and provider endpoint. Integration with openclaw would be a major PLUS. And then the "wake word" capability would be an item on the bottom right of the windows taskbar (to select settings) - so i can disable it if i want to conserve resources; and otherwise it just waits and acts like siri but with the model i selected - extra points if theres a way i can ask the model things via the wake word; and then the model can have te capability to respond via speech or via structured output - to the cursor location (it would always be structured output; but that way the user could request which output method they wanted  -and it could be routed easily) I"m currently using a program called "handy" on my pc and "voiceink" on my mac - i'm thinking this would be an extended version of those (which are explicit stt programs) by adding the extra features to allow hands free back and forth discourse with the ai model (via the hotkey or wakeword) - and still retain all the stt features of the other programs (i use parakeet v2 on my mac as the best local model for stt - though it may need some attention to get it working on arc - so thats why i have the paid api stt services above included as options - if we coudld use parakeet with the gpu that would be sweet thoguhj.
